# âœ… SERVER STARTUP GUIDE

## ğŸš€ QUICK START (Windows)

### **Option 1: Run Batch File (Easiest)**
```bash
cd C:\Users\rahul\PycharmProjects\PythonProject\job-scrapper
run_server.bat
```

### **Option 2: Run Directly in PowerShell**
```powershell
cd C:\Users\rahul\PycharmProjects\PythonProject\job-scrapper
python -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

### **Option 3: Run in CMD**
```cmd
cd C:\Users\rahul\PycharmProjects\PythonProject\job-scrapper
python -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

---

## ğŸ“‹ SETUP CHECKLIST

### **1. Install Dependencies (One-Time)**
```bash
pip install -r requirements.txt
```

### **2. Verify Installation**
```bash
python test_server_startup.py
```

Expected output:
```
âœ“ Test 1: Import FastAPI app
  âœ… App imported successfully

âœ“ Test 2: Check API routes
  âœ… Found 11 routes

âœ“ Test 3: Verify dependencies
  âœ… requests: installed
  âœ… pandas: installed
  âœ… beautifulsoup4: installed

âœ“ Test 4: Check Flair (optional)
  âœ… Flair installed

============================================================
âœ… ALL TESTS PASSED - SERVER READY!
============================================================
```

### **3. Start Server**
```bash
python -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

Expected output:
```
INFO:     Uvicorn running on http://127.0.0.1:8000
INFO:     Application startup complete
```

---

## ğŸŒ ACCESS API

### **Swagger UI (Interactive)**
```
http://127.0.0.1:8000/docs
```

### **ReDoc (Alternative)**
```
http://127.0.0.1:8000/redoc
```

### **Health Check**
```bash
curl http://127.0.0.1:8000/health
```

---

## ğŸ“Š AVAILABLE ENDPOINTS

### **Health & Info**
- `GET /health` - Health check
- `GET /` - API info

### **Resume Processing**
- `POST /upload-resume` - Upload resume + get recommendations
- `POST /analyze-resume` - Extract skills from resume
- `POST /get-recommendations` - Get recommendations (custom params)

### **Job Scraping**
- `POST /scrape-jobs` - Scrape from cached/API sources
- `POST /scrape-realtime` - Scrape from multiple APIs (RemoteOK, GitHub, Adzuna)
- `POST /scrape-linkedin` - **Scrape LinkedIn jobs with Flair skill extraction**

### **Job Recommendations**
- `POST /recommend-by-skills` - Get recommendations by skills
- `GET /jobs` - List all jobs (paginated)

---

## ğŸ§ª TEST ENDPOINTS

### **1. Health Check**
```bash
curl http://127.0.0.1:8000/health
```

### **2. Scrape Real-Time Jobs**
```bash
curl -X POST "http://127.0.0.1:8000/scrape-realtime?keyword=python&limit=30"
```

### **3. Scrape LinkedIn Jobs**
```bash
curl -X POST "http://localhost:8000/scrape-linkedin?position=Python%20Developer&max_pages=1"
```

### **4. Recommend by Skills**
```bash
curl -X POST "http://127.0.0.1:8000/recommend-by-skills" \
  -H "Content-Type: application/json" \
  -d '{"skills": ["Python", "Django", "REST"], "top_n": 5}'
```

---

## âŒ TROUBLESHOOTING

### **Issue: Port 8000 Already in Use**
```bash
# Kill the process using port 8000
netstat -ano | findstr :8000
taskkill /PID <PID> /F
```

### **Issue: Module Not Found**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### **Issue: Flair Model Download Slow**
- First API call may take 5-10 minutes (downloads 500MB model)
- Be patient, it only happens once
- Model is cached after first download

### **Issue: LinkedIn Scraper Returns No Jobs**
- LinkedIn structure changes frequently
- Try different search terms
- Check if LinkedIn website loads normally
- Wait 24-48 hours if you get 429 (too many requests)

---

## ğŸ“ PROJECT STRUCTURE

```
job-scrapper/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py           # All endpoints
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ scraper.py          # General scraper
â”‚   â”‚   â”œâ”€â”€ realtime_scraper.py # Real-time scraper
â”‚   â”‚   â”œâ”€â”€ linkedin_scraper.py # LinkedIn scraper (NEW!)
â”‚   â”‚   â”œâ”€â”€ pdf_parser.py       # PDF parsing
â”‚   â”‚   â”œâ”€â”€ skill_extractor.py  # Skill extraction
â”‚   â”‚   â”œâ”€â”€ matcher.py          # Job matching
â”‚   â”‚   â”œâ”€â”€ recommender.py      # Recommendations
â”‚   â”‚   â””â”€â”€ file_service.py     # File handling
â”‚   â”œâ”€â”€ db/
â”‚   â”‚   â””â”€â”€ fake_db.py          # Sample jobs
â”‚   â””â”€â”€ core/
â”‚       â””â”€â”€ config.py           # Configuration
â”œâ”€â”€ uploads/                    # Uploaded files
â”œâ”€â”€ scraped_data/               # Scraped job data
â”œâ”€â”€ requirements.txt            # Dependencies
â”œâ”€â”€ run_server.bat              # Windows batch file
â”œâ”€â”€ run_server.sh               # Linux/Mac shell script
â”œâ”€â”€ test_server_startup.py      # Startup verification
â””â”€â”€ test_linkedin_scraper.py    # LinkedIn scraper tests
```

---

## ğŸ¯ WORKFLOW

### **1. Start Server**
```bash
run_server.bat
# or
python -m uvicorn app.main:app --host 127.0.0.1 --port 8000 --reload
```

### **2. Open API Docs**
Go to: `http://127.0.0.1:8000/docs`

### **3. Test Endpoints**
Use Swagger UI to test any endpoint

### **4. Scrape LinkedIn**
```bash
curl -X POST "http://localhost:8000/scrape-linkedin?position=Python%20Developer&work_types=Remote&max_pages=2"
```

### **5. Check Results**
```bash
ls scraped_data/
cat scraped_data/linkedin_jobs_*.csv
```

---

## âœ… FINAL CHECKLIST

- âœ… Dependencies installed (`pip install -r requirements.txt`)
- âœ… All services created (scraper, realtime, linkedin)
- âœ… All endpoints working
- âœ… Flair NER integrated
- âœ… Startup script created
- âœ… Tests passing

---

## ğŸš€ YOU'RE READY!

Your complete Job Recommendation API is ready to use with:
- âœ… Resume parsing & skill extraction
- âœ… Real-time job scraping (3 sources)
- âœ… LinkedIn job scraping with Flair skills
- âœ… Automatic job matching
- âœ… Job recommendations
- âœ… CSV + JSON export

**Start the server and go to `http://127.0.0.1:8000/docs` to try it out!** ğŸ‰

